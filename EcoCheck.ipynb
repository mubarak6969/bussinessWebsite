{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRD7rUMb3VfLkkCH79xLG4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mubarak6969/bussinessWebsite/blob/main/EcoCheck.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy scikit-learn tensorflow flask simplejson\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as1wPw8Tvoel",
        "outputId": "7b520e20-0b5b-4cc7-e254-fb65a38238dc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Collecting simplejson\n",
            "  Downloading simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Downloading simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: simplejson\n",
            "Successfully installed simplejson-3.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "\n",
        "# Load the business listings data\n",
        "file_path = 'yelp_academic_dataset_business.json'\n",
        "\n",
        "# Read the JSON file line by line\n",
        "data = []\n",
        "with open(file_path, 'r') as file:\n",
        "    for line in file:\n",
        "        try:\n",
        "            record = json.loads(line)\n",
        "            data.append(record)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error decoding JSON at line: {e}\")\n",
        "            continue\n",
        "\n",
        "# Convert to DataFrame\n",
        "data = pd.DataFrame(data)\n",
        "print(data.head())\n",
        "\n",
        "# Check for empty data\n",
        "if data.empty:\n",
        "    raise ValueError(\"The dataset is empty. Please check the file content.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTb0I8s8vrtp",
        "outputId": "d596bfb2-82f6-4cb9-ead4-07856b8902d1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error decoding JSON at line: Unterminated string starting at: line 1 column 601 (char 600)\n",
            "              business_id                      name  \\\n",
            "0  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ   \n",
            "1  mpf3x-BjTdTEA3yCZrAYPw             The UPS Store   \n",
            "2  tUFrWirKiKi_TAnsVWINQQ                    Target   \n",
            "3  MTSW4McQd7CbVtyjqoe9mw        St Honore Pastries   \n",
            "4  mWMc6_wTdE0EUBKIGXDVfA  Perkiomen Valley Brewery   \n",
            "\n",
            "                           address           city state postal_code  \\\n",
            "0           1616 Chapala St, Ste 2  Santa Barbara    CA       93101   \n",
            "1  87 Grasso Plaza Shopping Center         Affton    MO       63123   \n",
            "2             5255 E Broadway Blvd         Tucson    AZ       85711   \n",
            "3                      935 Race St   Philadelphia    PA       19107   \n",
            "4                    101 Walnut St     Green Lane    PA       18054   \n",
            "\n",
            "    latitude   longitude  stars  review_count  is_open  \\\n",
            "0  34.426679 -119.711197    5.0             7        0   \n",
            "1  38.551126  -90.335695    3.0            15        1   \n",
            "2  32.223236 -110.880452    3.5            22        0   \n",
            "3  39.955505  -75.155564    4.0            80        1   \n",
            "4  40.338183  -75.471659    4.5            13        1   \n",
            "\n",
            "                                          attributes  \\\n",
            "0                      {'ByAppointmentOnly': 'True'}   \n",
            "1             {'BusinessAcceptsCreditCards': 'True'}   \n",
            "2  {'BikeParking': 'True', 'BusinessAcceptsCredit...   \n",
            "3  {'RestaurantsDelivery': 'False', 'OutdoorSeati...   \n",
            "4  {'BusinessAcceptsCreditCards': 'True', 'Wheelc...   \n",
            "\n",
            "                                          categories  \\\n",
            "0  Doctors, Traditional Chinese Medicine, Naturop...   \n",
            "1  Shipping Centers, Local Services, Notaries, Ma...   \n",
            "2  Department Stores, Shopping, Fashion, Home & G...   \n",
            "3  Restaurants, Food, Bubble Tea, Coffee & Tea, B...   \n",
            "4                          Brewpubs, Breweries, Food   \n",
            "\n",
            "                                               hours  \n",
            "0                                               None  \n",
            "1  {'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...  \n",
            "2  {'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...  \n",
            "3  {'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...  \n",
            "4  {'Wednesday': '14:0-22:0', 'Thursday': '16:0-2...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)  # Remove special characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces and strip\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing to relevant columns\n",
        "data['name'] = data['name'].apply(preprocess_text)\n",
        "data['address'] = data['address'].apply(preprocess_text)\n",
        "data['city'] = data['city'].apply(preprocess_text)\n",
        "data['categories'] = data['categories'].apply(lambda x: preprocess_text(x) if isinstance(x, str) else '')\n",
        "\n",
        "# Combine relevant fields into a single string for comparison\n",
        "data['combined'] = data['name'] + ' ' + data['address'] + ' ' + data['city'] + ' ' + data['categories']\n",
        "\n",
        "# Display the preprocessed data\n",
        "print(data[['combined']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLrTUsRxvwXJ",
        "outputId": "68e02ec0-5b7b-412b-b89a-c6ce5e2996d0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            combined\n",
            "0  abby rappoport lac cmq 1616 chapala st ste 2 s...\n",
            "1  the ups store 87 grasso plaza shopping center ...\n",
            "2  target 5255 e broadway blvd tucson department ...\n",
            "3  st honore pastries 935 race st philadelphia re...\n",
            "4  perkiomen valley brewery 101 walnut st green l...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pairs of business listings\n",
        "def create_pairs(data):\n",
        "    pairs = []\n",
        "    labels = []\n",
        "    for i in range(len(data)):\n",
        "        for j in range(i + 1, len(data)):\n",
        "            pair = [data['combined'].iloc[i], data['combined'].iloc[j]]\n",
        "            # Label as 1 if they are duplicates, 0 otherwise (for this example, we assume random pairing)\n",
        "            label = 1 if data['business_id'].iloc[i] == data['business_id'].iloc[j] else 0\n",
        "            pairs.append(pair)\n",
        "            labels.append(label)\n",
        "    return np.array(pairs), np.array(labels)\n",
        "\n",
        "# Create pairs and labels\n",
        "pairs, labels = create_pairs(data)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "pairs_train, pairs_test, labels_train, labels_test = train_test_split(pairs, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Number of training pairs: {len(pairs_train)}\")\n",
        "print(f\"Number of test pairs: {len(pairs_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "1Ux_dBwvv1xH",
        "outputId": "f57e781e-04df-4e8b-a818-86f570a2cf8d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-8665350ebf55>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Create pairs and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Split the data into training and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-8665350ebf55>\u001b[0m in \u001b[0;36mcreate_pairs\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mpair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'combined'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'combined'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;31m# Label as 1 if they are duplicates, 0 otherwise (for this example, we assume random pairing)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'business_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'business_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mpairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3867\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3868\u001b[0m             ):\n\u001b[0;32m-> 3869\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3871\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_mi\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   4400\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_item_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4402\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4403\u001b[0m         \u001b[0;34m\"\"\"Return the cached item, item represents a label indexer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sample_pairs(data, n_samples=1000):\n",
        "    pairs = []\n",
        "    labels = []\n",
        "    for _ in range(n_samples):\n",
        "        idx_a, idx_b = np.random.choice(len(data), 2, replace=False)\n",
        "        pair = [data['combined'].iloc[idx_a], data['combined'].iloc[idx_b]]\n",
        "        label = 1 if data['business_id'].iloc[idx_a] == data['business_id'].iloc[idx_b] else 0\n",
        "        if label == 0 and np.random.rand() > 0.3:  # Lower the threshold for skipping non-duplicate pairs\n",
        "            continue\n",
        "        pairs.append(pair)\n",
        "        labels.append(label)\n",
        "    return np.array(pairs), np.array(labels)\n",
        "\n",
        "\n",
        "\n",
        "pairs, labels = create_sample_pairs(data)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "pairs_train, pairs_test, labels_train, labels_test = train_test_split(pairs, labels, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "M7ejPm_Mv69L"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple base network\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "def create_base_network(input_shape):\n",
        "    input = Input(shape=input_shape)\n",
        "    x = layers.Dense(64, activation='relu', kernel_regularizer=l2(0.01))(input)  # Add L2 regularization\n",
        "    x = layers.Dropout(0.7)(x)  # Increased dropout rate\n",
        "    x = layers.Dense(32, activation='relu', kernel_regularizer=l2(0.01))(x)  # Add L2 regularization\n",
        "    x = layers.Dropout(0.7)(x)  # Increased dropout rate\n",
        "    return Model(input, x)\n",
        "\n",
        "\n",
        "input_shape = (300,)\n",
        "base_network = create_base_network(input_shape)\n",
        "\n",
        "input_a = Input(shape=input_shape)\n",
        "input_b = Input(shape=input_shape)\n",
        "\n",
        "processed_a = base_network(input_a)\n",
        "processed_b = base_network(input_b)\n",
        "\n",
        "distance = layers.Lambda(lambda x: tf.keras.backend.abs(x[0] - x[1]))([processed_a, processed_b])\n",
        "output = layers.Dense(1, activation='sigmoid')(distance)\n",
        "\n",
        "model = Model([input_a, input_b], output)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Convert the text pairs to numeric form using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=300)\n",
        "X_train_a = vectorizer.fit_transform(pairs_train[:, 0]).toarray()\n",
        "X_train_b = vectorizer.transform(pairs_train[:, 1]).toarray()\n",
        "X_test_a = vectorizer.transform(pairs_test[:, 0]).toarray()\n",
        "X_test_b = vectorizer.transform(pairs_test[:, 1]).toarray()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit([X_train_a, X_train_b], labels_train,\n",
        "                    validation_data=([X_test_a, X_test_b], labels_test),\n",
        "                    batch_size=64, epochs=6)  # Reduced number of epochs\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-Ym1DKY0Tat",
        "outputId": "c9bb14d0-5642-42c7-df87-9ba711dd30de"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.8348 - loss: 2.0672 - val_accuracy: 1.0000 - val_loss: 2.0427\n",
            "Epoch 2/6\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9037 - loss: 1.9474 - val_accuracy: 1.0000 - val_loss: 1.9428\n",
            "Epoch 3/6\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9344 - loss: 1.8388 - val_accuracy: 1.0000 - val_loss: 1.8510\n",
            "Epoch 4/6\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9657 - loss: 1.7030 - val_accuracy: 1.0000 - val_loss: 1.7670\n",
            "Epoch 5/6\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9931 - loss: 1.5960 - val_accuracy: 1.0000 - val_loss: 1.6897\n",
            "Epoch 6/6\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9957 - loss: 1.4763 - val_accuracy: 1.0000 - val_loss: 1.6182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate([X_test_a, X_test_b], labels_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrI0v8Ou0XAG",
        "outputId": "bf7c6338-9207-4615-8485-29917d046129"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 1.6077 \n",
            "Test Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_json('yelp_academic_dataset_business.json', lines=True)\n",
        "\n",
        "# Combine relevant columns for text-based comparison\n",
        "data['combined'] = data['name'] + ' ' + data['address'] + ' ' + data['categories'].fillna('') + ' ' + data['city']\n"
      ],
      "metadata": {
        "id": "8IqukUf-3786"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Select two businesses by their index or other unique identifier\n",
        "business_a = data.iloc[10]  # 10th business in the dataset\n",
        "business_b = data.iloc[20]  # 20th business in the dataset\n",
        "\n",
        "# Extract the combined text for each business\n",
        "input_a = business_a['combined']\n",
        "input_b = business_b['combined']\n",
        "\n",
        "print(f\"Business A: {input_a}\")\n",
        "print(f\"Business B: {input_b}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbwNIUnu6Jq2",
        "outputId": "f6b09559-3666-4cf4-d3c5-a9b49ba319c3"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Business A: Marshalls 21705 Village Lakes Sc Dr Department Stores, Shopping, Fashion Land O' Lakes\n",
            "Business B: Roast Coffeehouse and Wine Bar 10359 104 Street NW Coffee & Tea, Food, Cafes, Bars, Wine Bars, Restaurants, Nightlife Edmonton\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the inputs into TF-IDF vectors using the vectorizer fitted during training\n",
        "input_a_vec = vectorizer.transform([input_a]).toarray()\n",
        "input_b_vec = vectorizer.transform([input_b]).toarray()\n"
      ],
      "metadata": {
        "id": "j6Kvgqg06PCW"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction using the trained model\n",
        "prediction = model.predict([input_a_vec, input_b_vec])\n",
        "\n",
        "# Convert the prediction to a binary label\n",
        "predicted_label = 1 if prediction >= 0.5 else 0\n",
        "\n",
        "# Output the result\n",
        "if predicted_label == 1:\n",
        "    print(\"The businesses are likely duplicates.\")\n",
        "else:\n",
        "    print(\"The businesses are not duplicates.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uciXU406Ukn",
        "outputId": "0393eea4-37fc-4fea-d41b-80dfea074293"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step\n",
            "The businesses are not duplicates.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "38GH6HS39atv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}